{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mat\n",
    "import matplotlib.pyplot as plt\n",
    "import caffe\n",
    "import cv2\n",
    "import json\n",
    "import math\n",
    "#MODEL = 'ILSVRC' # ImageNet, don't use ImageNet, it wasn't trained on all categories\n",
    "MODEL = 'coco' # MS-Coco\n",
    "IMAGE_SIZE = 300 # 300x300 trained on coco or ILSVRC \n",
    "# I wonder if we can take the coco model and further train it on\n",
    "# http://image-net.org/synset?wnid=n02773838\n",
    "#IMAGE_SIZE = 512 # for 512x512 trained on coco\n",
    "THRESHOLD = 0.20 # for detection - percentage that the model is sure it's what you're looking for\n",
    "# There are 21 categories.... pick one color for each\n",
    "# just a tool for label finding\n",
    "any_in = lambda a, b: bool(set(a).intersection(b)) #for checking if a list contains elements of another\n",
    "COLORS = plt.cm.hsv(np.linspace(0, 1, 255)).tolist() #for picking colors of the boxes\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "#caffe.set_mode_cpu()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google.protobuf import text_format\n",
    "from caffe.proto import caffe_pb2\n",
    "\n",
    "# load COCO labels\n",
    "if MODEL == 'coco':\n",
    "    labelmap_file = 'data/coco/labelmap_coco.prototxt'\n",
    "else:\n",
    "    labelmap_file = 'data/ILSVRC2016/labelmap_ilsvrc_det.prototxt'\n",
    "file = open(labelmap_file, 'r')\n",
    "labelmap = caffe_pb2.LabelMap()\n",
    "text_format.Merge(str(file.read()), labelmap)\n",
    "\n",
    "def get_labelname(labelmap, labels):\n",
    "    num_labels = len(labelmap.item)\n",
    "    labelnames = []\n",
    "    if type(labels) is not list:\n",
    "        labels = [labels]\n",
    "    for label in labels:\n",
    "        found = False\n",
    "        for i in xrange(0, num_labels):\n",
    "            if label == labelmap.item[i].label:\n",
    "                found = True\n",
    "                labelnames.append(labelmap.item[i].display_name)\n",
    "                break\n",
    "        assert found == True\n",
    "    return labelnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadmodel():\n",
    "    if IMAGE_SIZE == 300 and MODEL == 'coco':\n",
    "        model = 'deploy300.prototxt'\n",
    "        weights = 'VGG_coco_SSD_300x300_iter_400000.caffemodel'\n",
    "    elif IMAGE_SIZE == 512 and MODEL == 'coco':\n",
    "        model = 'deploy512.prototxt'\n",
    "        weights = 'VGG_coco_SSD_512x512_iter_360000.caffemodel'\n",
    "    else:\n",
    "        model = 'deploy300a.prototxt'\n",
    "        weights = 'VGG_coco_SSD_300x300_iter'\n",
    "        # model = 'deployILSVRC.prototxt'\n",
    "        # weights = 'VGG_ILSVRC2016_SSD_300x300_iter_440000.caffemodel'\n",
    "    return caffe.Net(model, weights, caffe.TEST) #how you load a model with weights in Caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(frame):\n",
    "    # Frame must be IMG_SIZExIMG_SIZEx3\n",
    "    frame = cv2.resize(frame, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_LANCZOS4)\n",
    "    # Frame must then be BRG\n",
    "    if len(frame.shape) == 3:\n",
    "        frame = frame.transpose((2,0,1))\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect(image, net):\n",
    "    # (Batch size, channels, Image size, Image size) \n",
    "    # I wonder if we can increase the batch size and \n",
    "    # put a list of images together, but I guess that's more for training\n",
    "    net.blobs['data'].reshape(1,3,IMAGE_SIZE, IMAGE_SIZE)\n",
    "    # Transform the image to 1x3xSxS\n",
    "    net.blobs['data'].data[0,...] = image\n",
    "    # See ssd_detect.ipynb from Wei Liu, author of SSD\n",
    "    # https://github.com/weiliu89/caffe/blob/ssd/examples/ssd/ssd_detect.py\n",
    "    detections = net.forward()['detection_out']\n",
    "    # Parse the output tensors\n",
    "    det_label = detections[0,0,:,1]\n",
    "    det_conf = detections[0,0,:,2] #confidence\n",
    "    det_xmin = detections[0,0,:,3] #for bounding boxes per frame\n",
    "    det_ymin = detections[0,0,:,4]\n",
    "    det_xmax = detections[0,0,:,5]\n",
    "    det_ymax = detections[0,0,:,6]\n",
    "\n",
    "    # Keep only indices of detections with confidence higher than THRESHOLD\n",
    "    # in ssd_detect they keep it at 0.6, but that would be a confidence \n",
    "    # from the smaller set of PASCAL VOC cetegories. Coco has many more categories\n",
    "    # So a lower confidence still means a decent probability over the other categories\n",
    "    top_indices = [i for i, conf in enumerate(det_conf) if conf >= THRESHOLD]\n",
    "\n",
    "    top_conf = det_conf[top_indices]\n",
    "    top_label_indices = det_label[top_indices].tolist()\n",
    "    top_labels = get_labelname(labelmap, top_label_indices)\n",
    "    top_xmin = det_xmin[top_indices]\n",
    "    top_ymin = det_ymin[top_indices]\n",
    "    top_xmax = det_xmax[top_indices]\n",
    "    top_ymax = det_ymax[top_indices]\n",
    "    return (top_xmin, top_ymin, top_xmax, top_ymax, top_conf, top_labels, top_label_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcDist(coords1, coords2):\n",
    "    return np.linalg.norm(coords1-coords2)\n",
    "\n",
    "class ItemEntry:\n",
    "    def __init__(self, midx, midy, width, height, frame, label):\n",
    "        self.midCoords = np.array([midx, midy])\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.frame = frame\n",
    "        self.label = label\n",
    "\n",
    "class Item:\n",
    "    entries = []\n",
    "    ownerEntries = []\n",
    "    label = \"\"\n",
    "    notMoving = False\n",
    "    abandoned = False\n",
    "    ownerIdentified = False\n",
    "    offScreen = False\n",
    "    ownerDist = 999999\n",
    "    \n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "    def addEntry(self, entry):\n",
    "        self.entries.append(entry)\n",
    "    def addOwnerEntry(self, entry):\n",
    "        self.ownerEntries.append(entry)\n",
    "        self.ownerDist = calcDist(self.entries[-1].midCoords, entry.midCoords)\n",
    "    \n",
    "def loadvideo(filename, net):\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    k = 0 #counter for output file names of images that contain a detected bag\n",
    "    personItems = [] #Not using right now\n",
    "    bagItems = [] #Total catalog of bag items in the video\n",
    "    frameCount = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        frameCount += 1\n",
    "        ret, frame = cap.read()\n",
    "        if np.any(frame != 0):\n",
    "            try:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "            except:\n",
    "                return\n",
    "            frame_processed = preprocess(frame)\n",
    "            processed_det = detect(frame_processed, net)\n",
    "            top_xmin, top_ymin, top_xmax, top_ymax, top_conf, top_labels, top_label_indices = processed_det\n",
    "            print_image = True\n",
    "            if any_in(top_labels, ['suitcase', 'handbag', 'backpack', 'luggage', 'purse', 'baggage']) or print_image:\n",
    "                print_image = True\n",
    "                plt.rcParams['figure.figsize'] = (50, 50) #Matplotlib stuff that doesn't work?\n",
    "                plt.imshow(frame)\n",
    "                k += 1\n",
    "                currentAxis = plt.gca()\n",
    "                \n",
    "            framePeople = [] #People found this frame\n",
    "            frameBags = [] #Bags found this frame\n",
    "            for i in range(top_conf.shape[0]):\n",
    "                #print(top_conf)\n",
    "                xmin = int(round(top_xmin[i] * frame.shape[1]))\n",
    "                ymin = int(round(top_ymin[i] * frame.shape[0]))\n",
    "                xmax = int(round(top_xmax[i] * frame.shape[1]))\n",
    "                ymax = int(round(top_ymax[i] * frame.shape[0]))\n",
    "                score = top_conf[i]\n",
    "                label = int(top_label_indices[i])\n",
    "                label_name = top_labels[i]\n",
    "                display_txt = '%s: %.2f'%(label_name, score)\n",
    "                width = xmax-xmin+1\n",
    "                height = ymax-ymin+1\n",
    "                midx = xmin+(width)/2\n",
    "                midy = ymin+(height)/2\n",
    "                coords = (xmin, ymin), width, height\n",
    "                color = COLORS[label]\n",
    "                \n",
    "                \n",
    "                confThresh = 0.1 #Confidence level to accept an object\n",
    "                if score > confThresh and any_in([label_name], ['person', 'suitcase', 'handbag', 'backpack', 'luggage', 'purse', 'baggage']):\n",
    "                    if label_name == 'person':\n",
    "                        entry = ItemEntry(midx, midy, width, height, frameCount, 'person')\n",
    "                        framePeople.append(entry)\n",
    "                    else:\n",
    "                        entry = ItemEntry(midx, midy, width, height, frameCount, 'bag')\n",
    "                        frameBags.append(entry)\n",
    "                #print('blah')\n",
    "                #if any_in([label_name], ['suitcase', 'handbag', 'backpack', 'luggage', 'purse', 'baggage']):\n",
    "                    #print(str(display_txt) + ' - ' + str(coords))\n",
    "                    #centerCoords = (xmin+(xmax-xmin+1)/2, ymin+(ymax-ymin+1)/2), 3, 3\n",
    "                    #currentAxis.add_patch(plt.Rectangle(*centerCoords, fill=False, edgecolor=color, linewidth=2))\n",
    "                    #print(label_name)\n",
    "                \n",
    "                if print_image:\n",
    "                    currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=color, linewidth=16))\n",
    "                    currentAxis.text(xmin, ymin, display_txt, bbox={'facecolor':color, 'alpha':0.5}, fontsize=48)\n",
    "                \n",
    "                    centerCoords = (xmin+(xmax-xmin+1)/2, ymin+(ymax-ymin+1)/2), 3, 3\n",
    "                    currentAxis.add_patch(plt.Rectangle(*centerCoords, fill=False, edgecolor=color, linewidth=16))\n",
    "            \n",
    "            #print(str(len(framePeople)) + ' * ' + str(len(frameBags)))\n",
    "            \n",
    "            #If no people/bags found this frame, go to next frame\n",
    "            if len(framePeople) == 0 and len(frameBags) == 0:\n",
    "                print('None: ' + str(frameCount))\n",
    "                continue\n",
    "             \n",
    "            #Else if list of bags empty, initialize with first bags\n",
    "            elif len(bagItems) == 0 and len(frameBags) > 0:\n",
    "                for bagEntry in frameBags:\n",
    "                    newBag = Item('bag')\n",
    "                    newBag.addEntry(bagEntry)\n",
    "                    bagItems.append(newBag)\n",
    "\n",
    "            #Else if found bags, add frame information to bags that are closest\n",
    "            #TODO: Unused frameBags should be added to new bags\n",
    "            elif len(frameBags) > 0:\n",
    "                closestDist = 99999\n",
    "                closestIndex = -1\n",
    "                i = 0 #bagItem counter\n",
    "                j = 0 #frameBag counter\n",
    "                \n",
    "                while i < len(bagItems):\n",
    "                    while j < len(frameBags):\n",
    "                        dist = calcDist(bagItems[i].entries[-1].midCoords, frameBags[i].midCoords)\n",
    "                        if(dist < closestDist):\n",
    "                            closestDist = dist\n",
    "                            closestIndex = j\n",
    "                        j += 1\n",
    "                    bagItems[i].addEntry(frameBags[closestIndex])\n",
    "                    j = 0\n",
    "                    i += 1\n",
    "                \n",
    "            #Check for bags that are not moving, mark them as notMoving\n",
    "            notMovingFrameThresh = 5 #Number of frames needed to mark bags as notMoving\n",
    "            notMovingDistThresh = 2.0 #Max cartesian distance to identify bags as notMoving\n",
    "            for bag in bagItems:\n",
    "                if len(bag.entries) < notMovingFrameThresh+1 or bag.notMoving == True:\n",
    "                    continue\n",
    "                i = 0\n",
    "                #maxDist = -1\n",
    "                dist = 0\n",
    "                \n",
    "                #Calculate distances between frames to judge movement\n",
    "                while i < notMovingFrameThresh:\n",
    "                    dist += calcDist(bag.entries[-1-i].midCoords, bag.entries[-2-i].midCoords)\n",
    "                    i += 1\n",
    "                \n",
    "                #Bag is not moving\n",
    "                if dist <= notMovingDistThresh:\n",
    "                    bag.notMoving = True\n",
    "                    print('Not Moving: ' + str(k) + ' - ' + str(len(bag.ownerEntries)))\n",
    "                    \n",
    "            #For bags that are notMoving, add the closest owner\n",
    "            for bag in bagItems:\n",
    "                if bag.notMoving == True and bag.abandoned == False:\n",
    "                    \n",
    "                    #If first time being abandoned, find closest person as the owner\n",
    "                    if len(bag.ownerEntries) == 0:\n",
    "                        ind = 0\n",
    "                        closestDist = 99999\n",
    "                        closestIndex = -1\n",
    "                        while ind < len(framePeople):\n",
    "                            bagDist = calcDist(framePeople[ind].midCoords, bag.entries[-1].midCoords)\n",
    "                            if(bagDist < closestDist):\n",
    "                                closestDist = bagDist\n",
    "                                closestIndex = ind\n",
    "                            ind += 1\n",
    "\n",
    "                        #print(str(closestDist))\n",
    "                        firstOwnerDistThresh = 150.0 #Distance below which people can be chosen as the first owners\n",
    "                        if closestIndex != -1 and closestDist < firstOwnerDistThresh:\n",
    "                            bag.addOwnerEntry(framePeople[closestIndex])\n",
    "                            \n",
    "                    #Otherwise find closest person to previous owner entry\n",
    "                    else:\n",
    "                        ind = 0\n",
    "                        closestDist = 99999\n",
    "                        closestIndex = -1\n",
    "                        while ind < len(framePeople):\n",
    "                            bagDist = calcDist(framePeople[ind].midCoords, bag.ownerEntries[-1].midCoords)\n",
    "                            if(bagDist < closestDist):\n",
    "                                closestDist = bagDist\n",
    "                                closestIndex = ind\n",
    "                            ind += 1\n",
    "                        \n",
    "                        #If owner is close enough to previous owner, add the owner entry\n",
    "                        ownerDistThresh = 30.0 #Maximum distance from previous owner entry\n",
    "                        if closestDist < ownerDistThresh:\n",
    "                            bag.addOwnerEntry(framePeople[closestIndex])\n",
    "                        \n",
    "                        #Draw line connecting bag and owner\n",
    "                        currentAxis.plot([bag.entries[-1].midCoords[0],bag.ownerEntries[-1].midCoords[0]],[bag.entries[-1].midCoords[1],bag.ownerEntries[-1].midCoords[1]], color='b', linewidth=20)\n",
    "                        print(str(bag.ownerDist))\n",
    "                        \n",
    "                        #Check for bags that are too far from owner, mark them as abandoned\n",
    "                        abandonedDistThresh = 100.0 #Pixel distance from owner to identify notMoving bags as abandoned\n",
    "                        if bag.ownerDist > abandonedDistThresh:\n",
    "                            bag.abandoned = True\n",
    "                            print('Abandoned! ' + str(k) + ' - ' + str(len(bag.ownerEntries)))\n",
    "                            \n",
    "                elif bag.abandoned == True:\n",
    "                    #Draw line connecting bag and owner\n",
    "                    currentAxis.plot([bag.entries[-1].midCoords[0],bag.ownerEntries[-1].midCoords[0]],[bag.entries[-1].midCoords[1],bag.ownerEntries[-1].midCoords[1]], color='r', linewidth=3)\n",
    "                    print('Abandoned! ' + str(k) + ' - ' + str(len(bag.ownerEntries)))\n",
    "\n",
    "        figure_name = '%s_%05d.jpg' %('image', k)\n",
    "        if print_image:\n",
    "            plt.savefig(figure_name)\n",
    "            plt.clf()\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print 'how did we break?'\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = loadmodel()\n",
    "loadvideo('AVSS_AB_Easy_Clipped.mov', net)\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# no longer outputs the images here, but they are all in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
