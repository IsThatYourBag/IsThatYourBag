{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mat\n",
    "import matplotlib.pyplot as plt\n",
    "import caffe\n",
    "import cv2\n",
    "import json\n",
    "import math\n",
    "#MODEL = 'ILSVRC' # ImageNet, don't use ImageNet, it wasn't trained on all categories\n",
    "MODEL = 'coco' # MS-Coco\n",
    "IMAGE_SIZE = 300 # 300x300 trained on coco or ILSVRC \n",
    "# I wonder if we can take the coco model and further train it on\n",
    "# http://image-net.org/synset?wnid=n02773838\n",
    "#IMAGE_SIZE = 512 # for 512x512 trained on coco\n",
    "THRESHOLD = 0.20 # for detection - percentage that the model is sure it's what you're looking for\n",
    "# There are 21 categories.... pick one color for each\n",
    "# just a tool for label finding\n",
    "any_in = lambda a, b: bool(set(a).intersection(b)) #for checking if a list contains elements of another\n",
    "COLORS = plt.cm.hsv(np.linspace(0, 1, 255)).tolist() #for picking colors of the boxes\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "#caffe.set_mode_cpu()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google.protobuf import text_format\n",
    "from caffe.proto import caffe_pb2\n",
    "\n",
    "# load COCO labels\n",
    "if MODEL == 'coco':\n",
    "    labelmap_file = 'data/coco/labelmap_coco2.prototxt'\n",
    "else:\n",
    "    labelmap_file = 'data/ILSVRC2016/labelmap_ilsvrc_det.prototxt'\n",
    "file = open(labelmap_file, 'r')\n",
    "labelmap = caffe_pb2.LabelMap()\n",
    "text_format.Merge(str(file.read()), labelmap)\n",
    "\n",
    "def get_labelname(labelmap, labels):\n",
    "    num_labels = len(labelmap.item)\n",
    "    labelnames = []\n",
    "    if type(labels) is not list:\n",
    "        labels = [labels]\n",
    "    for label in labels:\n",
    "        found = False\n",
    "        for i in xrange(0, num_labels):\n",
    "            if label == labelmap.item[i].label:\n",
    "                found = True\n",
    "                labelnames.append(labelmap.item[i].display_name)\n",
    "                break\n",
    "        assert found == True\n",
    "    return labelnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadmodel():\n",
    "    if IMAGE_SIZE == 300 and MODEL == 'coco':\n",
    "        model = 'deploy300.prototxt'\n",
    "        weights = 'VGG_coco_SSD_300x300_iter_400000.caffemodel'\n",
    "    elif IMAGE_SIZE == 512 and MODEL == 'coco':\n",
    "        model = 'deploy512.prototxt'\n",
    "        weights = 'VGG_coco_SSD_512x512_iter_360000.caffemodel'\n",
    "    else:\n",
    "        model = 'deploy300a.prototxt'\n",
    "        weights = 'VGG_coco_SSD_300x300_iter'\n",
    "        # model = 'deployILSVRC.prototxt'\n",
    "        # weights = 'VGG_ILSVRC2016_SSD_300x300_iter_440000.caffemodel'\n",
    "    return caffe.Net(model, weights, caffe.TEST) #how you load a model with weights in Caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(frame):\n",
    "    # Frame must be IMG_SIZExIMG_SIZEx3\n",
    "    frame = cv2.resize(frame, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_LANCZOS4)\n",
    "    # Frame must then be BRG\n",
    "    if len(frame.shape) == 3:\n",
    "        frame = frame.transpose((2,0,1))\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect(image, net):\n",
    "    # (Batch size, channels, Image size, Image size) \n",
    "    # I wonder if we can increase the batch size and \n",
    "    # put a list of images together, but I guess that's more for training\n",
    "    net.blobs['data'].reshape(1,3,IMAGE_SIZE, IMAGE_SIZE)\n",
    "    # Transform the image to 1x3xSxS\n",
    "    net.blobs['data'].data[0,...] = image\n",
    "    # See ssd_detect.ipynb from Wei Liu, author of SSD\n",
    "    # https://github.com/weiliu89/caffe/blob/ssd/examples/ssd/ssd_detect.py\n",
    "    detections = net.forward()['detection_out']\n",
    "    # Parse the output tensors\n",
    "    det_label = detections[0,0,:,1]\n",
    "    det_conf = detections[0,0,:,2] #confidence\n",
    "    det_xmin = detections[0,0,:,3] #for bounding boxes per frame\n",
    "    det_ymin = detections[0,0,:,4]\n",
    "    det_xmax = detections[0,0,:,5]\n",
    "    det_ymax = detections[0,0,:,6]\n",
    "\n",
    "    # Keep only indices of detections with confidence higher than THRESHOLD\n",
    "    # in ssd_detect they keep it at 0.6, but that would be a confidence \n",
    "    # from the smaller set of PASCAL VOC cetegories. Coco has many more categories\n",
    "    # So a lower confidence still means a decent probability over the other categories\n",
    "    top_indices = [i for i, conf in enumerate(det_conf) if conf >= THRESHOLD]\n",
    "\n",
    "    top_conf = det_conf[top_indices]\n",
    "    top_label_indices = det_label[top_indices].tolist()\n",
    "    top_labels = get_labelname(labelmap, top_label_indices)\n",
    "    top_xmin = det_xmin[top_indices]\n",
    "    top_ymin = det_ymin[top_indices]\n",
    "    top_xmax = det_xmax[top_indices]\n",
    "    top_ymax = det_ymax[top_indices]\n",
    "    return (top_xmin, top_ymin, top_xmax, top_ymax, top_conf, top_labels, top_label_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcDist(coords1, coords2):\n",
    "    return np.linalg.norm(coords1-coords2)\n",
    "\n",
    "class ItemEntry:\n",
    "    def __init__(self, midx, midy, width, height, frame, label):\n",
    "        self.midCoords = np.array([midx, midy])\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.frame = frame\n",
    "        self.label = label\n",
    "\n",
    "class Item:\n",
    "    entries = []\n",
    "    ownerEntries = []\n",
    "    label = \"\"\n",
    "    notMoving = False\n",
    "    abandoned = False\n",
    "    ownerIdentified = False\n",
    "    offScreen = False\n",
    "    ownerDist = 999999\n",
    "    \n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "    def addEntry(self, entry):\n",
    "        self.entries.append(entry)\n",
    "    def addOwnerEntry(self, entry):\n",
    "        self.ownerEntries.append(entry)\n",
    "        self.ownerDist = calcDist(self.entries[-1].midCoords, entry.midCoords)\n",
    "    \n",
    "def loadvideo(filename, net):\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    k = 0 #counter for output file names of images that contain a detected bag\n",
    "    personItems = [] #Not using right now\n",
    "    bagItems = [] #Total catalog of bag items in the video\n",
    "    frameCount = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        frameCount += 1\n",
    "        ret, frame = cap.read()\n",
    "        if np.any(frame != 0):\n",
    "            try:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) \n",
    "            except:\n",
    "                return\n",
    "            frame_processed = preprocess(frame)\n",
    "            processed_det = detect(frame_processed, net)\n",
    "            top_xmin, top_ymin, top_xmax, top_ymax, top_conf, top_labels, top_label_indices = processed_det\n",
    "            print_image = True\n",
    "            if any_in(top_labels, ['suitcase', 'handbag', 'backpack', 'luggage', 'purse', 'baggage']) or print_image:\n",
    "                print_image = True\n",
    "                plt.rcParams['figure.figsize'] = (15, 15) #Matplotlib stuff that doesn't work?\n",
    "                plt.imshow(frame)\n",
    "                k += 1\n",
    "                currentAxis = plt.gca()\n",
    "                \n",
    "            framePeople = [] #People found this frame\n",
    "            frameBags = [] #Bags found this frame\n",
    "            for i in range(top_conf.shape[0]):\n",
    "                #print(top_conf)\n",
    "                xmin = int(round(top_xmin[i] * frame.shape[1]))\n",
    "                ymin = int(round(top_ymin[i] * frame.shape[0]))\n",
    "                xmax = int(round(top_xmax[i] * frame.shape[1]))\n",
    "                ymax = int(round(top_ymax[i] * frame.shape[0]))\n",
    "                score = top_conf[i]\n",
    "                label = int(top_label_indices[i])\n",
    "                label_name = top_labels[i]\n",
    "                display_txt = '%s: %.2f'%(label_name, score)\n",
    "                width = xmax-xmin+1\n",
    "                height = ymax-ymin+1\n",
    "                midx = xmin+(width)/2\n",
    "                midy = ymin+(height)/2\n",
    "                coords = (xmin, ymin), width, height\n",
    "                color = COLORS[label]\n",
    "                \n",
    "                \n",
    "                confThresh = 0.1 #Confidence level to accept an object\n",
    "                if score > confThresh and any_in([label_name], ['person', 'suitcase', 'handbag', 'backpack', 'luggage', 'purse', 'baggage']):\n",
    "                    if label_name == 'person':\n",
    "                        entry = ItemEntry(midx, midy, width, height, frameCount, 'person')\n",
    "                        framePeople.append(entry)\n",
    "                    else:\n",
    "                        entry = ItemEntry(midx, midy, width, height, frameCount, 'bag')\n",
    "                        frameBags.append(entry)\n",
    "                #print('blah')\n",
    "                #if any_in([label_name], ['suitcase', 'handbag', 'backpack', 'luggage', 'purse', 'baggage']):\n",
    "                    #print(str(display_txt) + ' - ' + str(coords))\n",
    "                    #centerCoords = (xmin+(xmax-xmin+1)/2, ymin+(ymax-ymin+1)/2), 3, 3\n",
    "                    #currentAxis.add_patch(plt.Rectangle(*centerCoords, fill=False, edgecolor=color, linewidth=2))\n",
    "                    #print(label_name)\n",
    "                \n",
    "                if print_image:\n",
    "                    #currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=color, linewidth=16))\n",
    "                    #currentAxis.text(xmin, ymin, display_txt, bbox={'facecolor':color, 'alpha':0.5}, fontsize=48)\n",
    "                    currentAxis.add_patch(plt.Rectangle(*coords, fill=False, edgecolor=color, linewidth=3))\n",
    "                    currentAxis.text(xmin, ymin, display_txt, bbox={'facecolor':color, 'alpha':0.5})\n",
    "                \n",
    "                    centerCoords = (xmin+(xmax-xmin+1)/2, ymin+(ymax-ymin+1)/2), 3, 3\n",
    "                    #currentAxis.add_patch(plt.Rectangle(*centerCoords, fill=False, edgecolor=color, linewidth=16))\n",
    "                    currentAxis.add_patch(plt.Rectangle(*centerCoords, fill=False, edgecolor=color, linewidth=3))\n",
    "            \n",
    "            #print(str(len(framePeople)) + ' * ' + str(len(frameBags)))\n",
    "            \n",
    "            #If no people/bags found this frame, go to next frame\n",
    "            if len(framePeople) == 0 and len(frameBags) == 0:\n",
    "                print('None: ' + str(frameCount))\n",
    "                continue\n",
    "             \n",
    "            #Else if list of bags empty, initialize with first bags\n",
    "            elif len(bagItems) == 0 and len(frameBags) > 0:\n",
    "                for bagEntry in frameBags:\n",
    "                    newBag = Item('bag')\n",
    "                    newBag.addEntry(bagEntry)\n",
    "                    bagItems.append(newBag)\n",
    "\n",
    "            #Else if found bags, add frame information to bags that are closest\n",
    "            #TODO: Unused frameBags should be added to new bags\n",
    "            elif len(frameBags) > 0:\n",
    "                closestDist = 99999\n",
    "                closestIndex = -1\n",
    "                i = 0 #bagItem counter\n",
    "                j = 0 #frameBag counter\n",
    "                \n",
    "                while i < len(bagItems):\n",
    "                    while j < len(frameBags):\n",
    "                        dist = calcDist(bagItems[i].entries[-1].midCoords, frameBags[i].midCoords)\n",
    "                        if(dist < closestDist):\n",
    "                            closestDist = dist\n",
    "                            closestIndex = j\n",
    "                        j += 1\n",
    "                    bagItems[i].addEntry(frameBags[closestIndex])\n",
    "                    j = 0\n",
    "                    i += 1\n",
    "                \n",
    "            #Check for bags that are not moving, mark them as notMoving\n",
    "            notMovingFrameThresh = 5 #Number of frames needed to mark bags as notMoving\n",
    "            notMovingDistThresh = 2.0 #Max cartesian distance to identify bags as notMoving\n",
    "            for bag in bagItems:\n",
    "                if len(bag.entries) < notMovingFrameThresh+1 or bag.notMoving == True:\n",
    "                    continue\n",
    "                i = 0\n",
    "                #maxDist = -1\n",
    "                dist = 0\n",
    "                \n",
    "                #Calculate distances between frames to judge movement\n",
    "                while i < notMovingFrameThresh:\n",
    "                    dist += calcDist(bag.entries[-1-i].midCoords, bag.entries[-2-i].midCoords)\n",
    "                    i += 1\n",
    "                \n",
    "                #Bag is not moving\n",
    "                if dist <= notMovingDistThresh:\n",
    "                    bag.notMoving = True\n",
    "                    print('Not Moving: ' + str(k) + ' - ' + str(len(bag.ownerEntries)))\n",
    "                    \n",
    "            #For bags that are notMoving, add the closest owner\n",
    "            for bag in bagItems:\n",
    "                if bag.notMoving == True:\n",
    "                    \n",
    "                    #If first time being abandoned, find closest person as the owner\n",
    "                    if len(bag.ownerEntries) == 0:\n",
    "                        ind = 0\n",
    "                        closestDist = 99999\n",
    "                        closestIndex = -1\n",
    "                        while ind < len(framePeople):\n",
    "                            bagDist = calcDist(framePeople[ind].midCoords, bag.entries[-1].midCoords)\n",
    "                            if(bagDist < closestDist):\n",
    "                                closestDist = bagDist\n",
    "                                closestIndex = ind\n",
    "                            ind += 1\n",
    "\n",
    "                        #print(str(closestDist))\n",
    "                        firstOwnerDistThresh = 150.0 #Distance below which people can be chosen as the first owners\n",
    "                        if closestIndex != -1 and closestDist < firstOwnerDistThresh:\n",
    "                            bag.addOwnerEntry(framePeople[closestIndex])\n",
    "                            \n",
    "                    #Otherwise find closest person to previous owner entry\n",
    "                    else:\n",
    "                        ind = 0\n",
    "                        closestDist = 99999\n",
    "                        closestIndex = -1\n",
    "                        while ind < len(framePeople):\n",
    "                            bagDist = calcDist(framePeople[ind].midCoords, bag.ownerEntries[-1].midCoords)\n",
    "                            if(bagDist < closestDist):\n",
    "                                closestDist = bagDist\n",
    "                                closestIndex = ind\n",
    "                            ind += 1\n",
    "                        \n",
    "                        #If owner is close enough to previous owner, add the owner entry\n",
    "                        ownerDistThresh = 75.0 #Maximum distance from previous owner entry\n",
    "                        if closestDist < ownerDistThresh:\n",
    "                            bag.addOwnerEntry(framePeople[closestIndex])\n",
    "                    \n",
    "                        #Check for bags that are too far from owner, mark them as abandoned\n",
    "                        abandonedDistThresh = 300.0 #Pixel distance from owner to identify notMoving bags as abandoned\n",
    "                        if bag.ownerDist > abandonedDistThresh:\n",
    "                            bag.abandoned = True\n",
    "                            print('Abandoned! ' + str(k) + ' - ' + str(len(bag.ownerEntries)))\n",
    "                        \n",
    "                        #Draw line connecting bag and owner\n",
    "                        if bag.abandoned == True:\n",
    "                            currentAxis.plot([bag.entries[-1].midCoords[0],bag.ownerEntries[-1].midCoords[0]],[bag.entries[-1].midCoords[1],bag.ownerEntries[-1].midCoords[1]], color='r', linewidth=4)\n",
    "                            #currentAxis.plot([bag.entries[-1].midCoords[0],bag.ownerEntries[-1].midCoords[0]],[bag.entries[-1].midCoords[1],bag.ownerEntries[-1].midCoords[1]], color='r', linewidth=16)\n",
    "                        else:\n",
    "                            currentAxis.plot([bag.entries[-1].midCoords[0],bag.ownerEntries[-1].midCoords[0]],[bag.entries[-1].midCoords[1],bag.ownerEntries[-1].midCoords[1]], color='g', linewidth=4)\n",
    "                            #currentAxis.plot([bag.entries[-1].midCoords[0],bag.ownerEntries[-1].midCoords[0]],[bag.entries[-1].midCoords[1],bag.ownerEntries[-1].midCoords[1]], color='g', linewidth=16)\n",
    "                        \n",
    "                        print('Frame: '+str(k)+' - OwnerDist: '+str(bag.ownerDist))\n",
    "                        \n",
    "\n",
    "        figure_name = 'images-original/%s_%05d.jpg' %('image', k)\n",
    "        if print_image:\n",
    "            plt.savefig(figure_name)\n",
    "            plt.clf()\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print 'how did we break?'\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Moving: 314 - 0\n",
      "Frame: 315 - OwnerDist: 67.4166151627\n",
      "Frame: 316 - OwnerDist: 66.4078308635\n",
      "Frame: 317 - OwnerDist: 59.7745765355\n",
      "Frame: 318 - OwnerDist: 59.7745765355\n",
      "Frame: 319 - OwnerDist: 58.8217646794\n",
      "Frame: 320 - OwnerDist: 58.8217646794\n",
      "Frame: 321 - OwnerDist: 56.302753041\n",
      "Frame: 322 - OwnerDist: 59.7745765355\n",
      "Frame: 323 - OwnerDist: 57.5673518585\n",
      "Frame: 324 - OwnerDist: 60.0832755432\n",
      "Frame: 325 - OwnerDist: 60.0832755432\n",
      "Frame: 326 - OwnerDist: 62.6418390535\n",
      "Frame: 327 - OwnerDist: 58.9406481132\n",
      "Frame: 328 - OwnerDist: 58.463663929\n",
      "Frame: 329 - OwnerDist: 57.4891294072\n",
      "Frame: 330 - OwnerDist: 56.2938717802\n",
      "Frame: 331 - OwnerDist: 55.3172667438\n",
      "Frame: 332 - OwnerDist: 53.3666562565\n",
      "Frame: 333 - OwnerDist: 53.9351462406\n",
      "Frame: 334 - OwnerDist: 53.9351462406\n",
      "Frame: 335 - OwnerDist: 52.9528091795\n",
      "Frame: 336 - OwnerDist: 53.1507290637\n",
      "Frame: 337 - OwnerDist: 52.7730992078\n",
      "Frame: 338 - OwnerDist: 52.7730992078\n",
      "Frame: 339 - OwnerDist: 52.7730992078\n",
      "Frame: 340 - OwnerDist: 52.7730992078\n",
      "Frame: 341 - OwnerDist: 53.7587202229\n",
      "Frame: 342 - OwnerDist: 49.6487663492\n",
      "Frame: 343 - OwnerDist: 54.7448627727\n",
      "Frame: 344 - OwnerDist: 54.7448627727\n",
      "Frame: 345 - OwnerDist: 54.7448627727\n",
      "Frame: 346 - OwnerDist: 54.7448627727\n",
      "Frame: 347 - OwnerDist: 54.7448627727\n",
      "Frame: 348 - OwnerDist: 54.7448627727\n",
      "Frame: 349 - OwnerDist: 54.7448627727\n",
      "Frame: 350 - OwnerDist: 54.7448627727\n",
      "Frame: 351 - OwnerDist: 54.7448627727\n",
      "Frame: 352 - OwnerDist: 54.7448627727\n",
      "Frame: 353 - OwnerDist: 54.7448627727\n",
      "Frame: 354 - OwnerDist: 54.7448627727\n",
      "Frame: 355 - OwnerDist: 54.7448627727\n",
      "Frame: 356 - OwnerDist: 54.7448627727\n",
      "Frame: 357 - OwnerDist: 54.7448627727\n",
      "Frame: 358 - OwnerDist: 54.7448627727\n",
      "Frame: 359 - OwnerDist: 54.7448627727\n",
      "Frame: 360 - OwnerDist: 54.7448627727\n",
      "Frame: 361 - OwnerDist: 54.7448627727\n",
      "Frame: 362 - OwnerDist: 54.7448627727\n",
      "Frame: 363 - OwnerDist: 54.7448627727\n",
      "Frame: 364 - OwnerDist: 54.7448627727\n",
      "Frame: 365 - OwnerDist: 105.223571504\n",
      "Frame: 366 - OwnerDist: 113.13708499\n",
      "Frame: 367 - OwnerDist: 110.887330205\n",
      "Frame: 368 - OwnerDist: 110.887330205\n",
      "Frame: 369 - OwnerDist: 108.779593675\n",
      "Frame: 370 - OwnerDist: 105.385008422\n",
      "Frame: 371 - OwnerDist: 102.313244499\n",
      "Frame: 372 - OwnerDist: 106.230880633\n",
      "Frame: 373 - OwnerDist: 98.1835016691\n",
      "Frame: 374 - OwnerDist: 101.123686642\n",
      "Frame: 375 - OwnerDist: 101.123686642\n",
      "Frame: 376 - OwnerDist: 102.078401241\n",
      "Frame: 377 - OwnerDist: 98.0815986819\n",
      "Frame: 378 - OwnerDist: 106.042444332\n",
      "Frame: 379 - OwnerDist: 108.018516931\n",
      "Frame: 380 - OwnerDist: 103.07764064\n",
      "Frame: 381 - OwnerDist: 101.079176886\n",
      "Frame: 382 - OwnerDist: 100.079968026\n",
      "Frame: 383 - OwnerDist: 100.079968026\n",
      "Frame: 384 - OwnerDist: 103.07764064\n",
      "Frame: 385 - OwnerDist: 100.079968026\n",
      "Frame: 386 - OwnerDist: 103.07764064\n",
      "Frame: 387 - OwnerDist: 103.043680059\n",
      "Frame: 388 - OwnerDist: 103.07764064\n",
      "Frame: 389 - OwnerDist: 104.120122935\n",
      "Frame: 390 - OwnerDist: 109.16501271\n",
      "Frame: 391 - OwnerDist: 108.115678789\n",
      "Frame: 392 - OwnerDist: 109.073369802\n",
      "Frame: 393 - OwnerDist: 107.168092266\n",
      "Frame: 394 - OwnerDist: 109.16501271\n",
      "Frame: 395 - OwnerDist: 108.115678789\n",
      "Frame: 396 - OwnerDist: 110.163514831\n",
      "Frame: 397 - OwnerDist: 108.166538264\n",
      "Frame: 398 - OwnerDist: 112.160599142\n",
      "Frame: 399 - OwnerDist: 104.172933145\n",
      "Frame: 400 - OwnerDist: 104.120122935\n",
      "Frame: 401 - OwnerDist: 103.17460928\n",
      "Frame: 402 - OwnerDist: 108.226614102\n",
      "Frame: 403 - OwnerDist: 104.172933145\n",
      "Frame: 404 - OwnerDist: 102.239913928\n",
      "Frame: 405 - OwnerDist: 103.17460928\n",
      "Frame: 406 - OwnerDist: 109.224539367\n",
      "Frame: 407 - OwnerDist: 107.168092266\n",
      "Frame: 408 - OwnerDist: 105.233074649\n",
      "Frame: 409 - OwnerDist: 105.171288858\n",
      "Frame: 410 - OwnerDist: 100.319489632\n",
      "Frame: 411 - OwnerDist: 110.22250224\n",
      "Frame: 412 - OwnerDist: 94.3398113206\n",
      "Frame: 413 - OwnerDist: 101.242283657\n",
      "Frame: 414 - OwnerDist: 107.228727494\n",
      "Frame: 415 - OwnerDist: 100.319489632\n",
      "Frame: 416 - OwnerDist: 106.301458127\n",
      "Frame: 417 - OwnerDist: 97.2522493313\n",
      "Frame: 418 - OwnerDist: 113.216606556\n",
      "Frame: 419 - OwnerDist: 105.304320899\n",
      "Frame: 420 - OwnerDist: 103.310212467\n",
      "Frame: 421 - OwnerDist: 100.244700608\n",
      "Frame: 422 - OwnerDist: 106.230880633\n",
      "Frame: 423 - OwnerDist: 108.295890965\n",
      "Frame: 424 - OwnerDist: 101.400197238\n",
      "Frame: 425 - OwnerDist: 109.224539367\n",
      "Frame: 426 - OwnerDist: 107.29864864\n",
      "Frame: 427 - OwnerDist: 102.313244499\n",
      "Frame: 428 - OwnerDist: 108.295890965\n",
      "Frame: 429 - OwnerDist: 109.224539367\n",
      "Frame: 430 - OwnerDist: 109.370928496\n",
      "Frame: 431 - OwnerDist: 106.301458127\n",
      "Frame: 432 - OwnerDist: 109.293183685\n",
      "Frame: 433 - OwnerDist: 106.301458127\n",
      "Frame: 434 - OwnerDist: 107.29864864\n",
      "Frame: 435 - OwnerDist: 106.301458127\n",
      "Frame: 436 - OwnerDist: 108.295890965\n",
      "Frame: 437 - OwnerDist: 107.228727494\n",
      "Frame: 438 - OwnerDist: 112.285350781\n",
      "Frame: 439 - OwnerDist: 111.287914887\n",
      "Frame: 440 - OwnerDist: 111.287914887\n",
      "Frame: 441 - OwnerDist: 107.377837564\n",
      "Frame: 442 - OwnerDist: 113.441614939\n",
      "Frame: 443 - OwnerDist: 111.36426716\n",
      "Frame: 444 - OwnerDist: 112.361025271\n",
      "Frame: 445 - OwnerDist: 105.475115549\n",
      "Frame: 446 - OwnerDist: 103.310212467\n",
      "Frame: 447 - OwnerDist: 110.3675677\n",
      "Frame: 448 - OwnerDist: 108.295890965\n",
      "Frame: 449 - OwnerDist: 112.361025271\n",
      "Frame: 450 - OwnerDist: 108.295890965\n",
      "Frame: 451 - OwnerDist: 108.374351209\n",
      "Frame: 452 - OwnerDist: 109.370928496\n",
      "Frame: 453 - OwnerDist: 112.361025271\n",
      "Frame: 454 - OwnerDist: 109.370928496\n",
      "Frame: 455 - OwnerDist: 117.273185341\n",
      "Frame: 456 - OwnerDist: 111.36426716\n",
      "Frame: 457 - OwnerDist: 107.466273779\n",
      "Frame: 458 - OwnerDist: 109.370928496\n",
      "Frame: 459 - OwnerDist: 110.290525432\n",
      "Frame: 460 - OwnerDist: 109.370928496\n",
      "Frame: 461 - OwnerDist: 116.27553483\n",
      "Frame: 462 - OwnerDist: 110.3675677\n",
      "Frame: 463 - OwnerDist: 110.3675677\n",
      "Frame: 464 - OwnerDist: 102.313244499\n",
      "Frame: 465 - OwnerDist: 99.4082491547\n",
      "Frame: 466 - OwnerDist: 105.475115549\n",
      "Frame: 467 - OwnerDist: 104.307238483\n",
      "Frame: 468 - OwnerDist: 107.377837564\n",
      "Frame: 469 - OwnerDist: 105.385008422\n",
      "Frame: 470 - OwnerDist: 105.475115549\n",
      "Frame: 471 - OwnerDist: 104.479663093\n",
      "Frame: 472 - OwnerDist: 109.370928496\n",
      "Frame: 473 - OwnerDist: 98.412397593\n",
      "Frame: 474 - OwnerDist: 101.400197238\n",
      "Frame: 475 - OwnerDist: 106.38138935\n",
      "Frame: 476 - OwnerDist: 108.461974904\n",
      "Frame: 477 - OwnerDist: 104.388696706\n",
      "Frame: 478 - OwnerDist: 107.377837564\n",
      "Frame: 479 - OwnerDist: 97.3293378175\n",
      "Frame: 480 - OwnerDist: 109.457754408\n",
      "Frame: 481 - OwnerDist: 105.475115549\n",
      "Frame: 482 - OwnerDist: 106.470653234\n",
      "Frame: 483 - OwnerDist: 98.412397593\n",
      "Frame: 484 - OwnerDist: 101.400197238\n",
      "Frame: 485 - OwnerDist: 107.377837564\n",
      "Frame: 486 - OwnerDist: 106.301458127\n",
      "Frame: 487 - OwnerDist: 110.3675677\n",
      "Frame: 488 - OwnerDist: 105.475115549\n",
      "Frame: 489 - OwnerDist: 106.301458127\n",
      "Frame: 490 - OwnerDist: 108.374351209\n",
      "Frame: 491 - OwnerDist: 106.38138935\n",
      "Frame: 492 - OwnerDist: 117.273185341\n",
      "Frame: 493 - OwnerDist: 117.345643294\n",
      "Frame: 494 - OwnerDist: 117.209214655\n",
      "Frame: 495 - OwnerDist: 104.235310716\n",
      "Frame: 496 - OwnerDist: 105.304320899\n",
      "Frame: 497 - OwnerDist: 105.304320899\n",
      "Frame: 498 - OwnerDist: 99.1816515289\n",
      "Frame: 499 - OwnerDist: 99.1816515289\n",
      "Frame: 500 - OwnerDist: 99.1816515289\n",
      "Frame: 501 - OwnerDist: 99.1816515289\n",
      "Frame: 502 - OwnerDist: 99.1816515289\n",
      "Frame: 503 - OwnerDist: 99.1816515289\n",
      "Frame: 504 - OwnerDist: 99.1816515289\n",
      "Frame: 505 - OwnerDist: 99.1816515289\n",
      "Frame: 506 - OwnerDist: 105.0428484\n",
      "Frame: 507 - OwnerDist: 112.040171367\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fa7355e61c66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloadvideo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AVSS_AB_Easy_Clipped.mov'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-77293ee65d40>\u001b[0m in \u001b[0;36mloadvideo\u001b[0;34m(filename, net)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mframeCount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2390384e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = loadmodel()\n",
    "loadvideo('AVSS_AB_Easy_Clipped.mov', net)\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# no longer outputs the images here, but they are all in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
